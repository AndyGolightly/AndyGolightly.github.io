\documentclass[12pt,BCOR2mm,DIV14,english]{scrreprt}
\usepackage[pdftex,pdftitle={Bayesian computation and modelling III},pdflang={en-GB}]{hyperref}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{babel,comment}
\usepackage{listings}
%\usepackage{minted}
%\usepackage{blindtext}
\KOMAoption{chapterprefix}{true}

\usepackage{fancyvrb}

\usepackage{paralist}
\usepackage{natbib}
\usepackage{microtype, booktabs}
\usepackage{amsthm,amsmath,amsfonts,psfrag}
\usepackage{latexsym}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{graphicx}
\graphicspath{{../graphics/}}
\addtolength{\parskip}{1ex}
\pagestyle{fancy}
\lhead{MATH3421}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}

\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{listings}

\usepackage{bm}
\usepackage{xcolor}

\lstset{ 
  language=R,                     % the language of the code
  basicstyle=\small\ttfamily, % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\small\color{Blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  %keywordstyle=\color{RoyalBlue},      % keyword style
  keywordstyle=\color{purple},	
  commentstyle=\color{violet},   % comment style
  %stringstyle=\color{ForestGreen}      % string literal style
  stringstyle=\color{RoyalBlue} 
} 



%\newcommand{\pr}[2][]{\ensuremath{\mathrm{Pr}_{#1}\!\left(#2\right)}}
\newenvironment{myhighlight}{\textit}{}
%\renewenvironment{emph}{\textbf}{}
\newcommand{\Exp}[2][]{\ensuremath{\mathrm{Exp}\left(#2\right)}}
\newcommand{\Bin}[2][]{\ensuremath{\mathrm{Bin}\left(#2\right)}}
\newcommand{\Po}[2][]{\ensuremath{\mathrm{Po}\left(#2\right)}}
\newcommand{\cov}[2][]{\ensuremath{\mathrm{Cov}\left(#2\right)}}
\newcommand{\cor}[2][]{\ensuremath{\mathrm{Cor}\left(#2\right)}}
\newcommand{\diag}[2][]{\ensuremath{\mathrm{diag}\left(#2\right)}}
\newcommand{\given}{\ensuremath{\ |\ }}
\newcommand{\stationary}{\ensuremath{\vec{\pi}}}
\newcommand{\identity}{\ensuremath{\vec{I}}}
\renewcommand{\vec}[1]{\underline{#1}}
\newcommand{\remove}[1]{}
%\newcommand{\cover}[2]{\emph{#1}}
\newcommand{\cover}[2]{{\color{red}{#2}}}

\newcommand{\newnotes}{}\newcommand{\newstud}{}

\newcommand{\smallnotes}{\renewcommand{\newnotes}{\newpage}
   \newenvironment{soln}{\color{red}\begin{sloppypar}\bigskip\noindent
      \textbf{\large Solution}\\~\\\noindent}{\end{sloppypar}\normalcolor}
   \newenvironment{ggap}{\color{red}\begin{sloppypar}\bigskip\noindent}{\end{sloppypar}\normalcolor}}
% full notes - with solns (staff version)
\newcommand{\notes}{\renewcommand{\newstud}{\newpage}
   \newenvironment{soln}{\begin{sloppypar}\bigskip\noindent
      \textbf{\large Solution}\\~\color{red}\begingroup\LARGE
      \noindent\\}{\endgroup\color{red}\end{sloppypar}}
   \newenvironment{ggap}{\color{red}\begin{sloppypar}\bigskip\noindent
      \begingroup\LARGE\noindent}{\endgroup\end{sloppypar}\normalcolor}}
% full notes - with solns (student version)
\newcommand{\studnotes}{\renewcommand{\newstud}{\newpage}
   \newenvironment{soln}{\begin{sloppypar}\bigskip\noindent
      \textbf{\large Solution}\\~\color{white}\begingroup\LARGE
      \noindent\\}{\endgroup\color{white}\end{sloppypar}}
   \newenvironment{ggap}{\begin{sloppypar}\bigskip\noindent\color{white}
      \begingroup\LARGE\noindent}{\endgroup\color{white}\end{sloppypar}}}

\newtheoremstyle{exmp}% hnamei
{3pt}% hSpace abovei
{3pt}% hSpace belowi
{}% hBody fonti
{}% hIndent amounti1
{\bfseries}% hTheorem head fonti
{:}% hPunctuation after theorem headi
{.5em}% hSpace after theorem headi2
{}% hTheorem head spec (can be left empty, meaning `normal')i
\theoremstyle{exmp}
\newtheorem{example}{Example}[section]

%\def \var{{\textrm{Var}}}
%\newcommand{\E}[2][]{\ensuremath{\mathrm{E}\left[#2\right]}}
\def \R{\mathbb{R}}
\def \Z{\mathbb{Z}}
\def \proof{\noindent{\bfseries Proof:  }}
\def \eproof{\qed\vskip .3cm}
\def \union{\cup}
\def \intersect{\cap}
\newcommand{\ex}[2][]{\ensuremath{\mathrm{E}_{#1}\!\left[#2\right]}}
\newcommand{\var}[2][]{\ensuremath{\mathrm{Var}_{#1}\left(#2\right)}}
%\renewcommand{\det}[1][]{\ensuremath{\mathrm{det}\left(#1\right)}}
\newtheorem{defn}{Definition}[section]
%\newtheorem*{example}{Example}
\newtheorem{result}{Result}[section]
\newtheorem{algorithm}{Algorithm}[section]

\newcommand{\bmX}{\boldsymbol{X}}
\newcommand{\bmx}{\boldsymbol{x}}
\newcommand{\bmy}{\boldsymbol{y}}
\newcommand{\bmw}{\boldsymbol{w}}
\newcommand{\bmm}{\boldsymbol{m}}
\newcommand{\bmz}{\boldsymbol{z}}
\newcommand{\bms}{\boldsymbol{s}}
\newcommand{\bmtheta}{\boldsymbol{\theta}}
\newcommand{\bmTheta}{\boldsymbol{\Theta}}
\newcommand{\bmphi}{\boldsymbol{\phi}}
\newcommand{\bmpsi}{\boldsymbol{\psi}}
\newcommand{\bmpi}{\boldsymbol{\pi}}
\newcommand{\bmnu}{\boldsymbol{\nu}}
\newcommand{\bmmu}{\boldsymbol{\mu}}
\newcommand{\bmepsilon}{\boldsymbol{\epsilon}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathrm{Var}}
\renewcommand{\familydefault}{\sfdefault}

\def \prior{\pi({\theta})}
%\def \posterior{f_{{\Theta}|\bmX}(\theta |\bmx)}
\def \posterior{f(\theta |\bmx)}
\def \posteriorpi{\pi(\theta |\bmx)}
%\def \likelihoodf{f_{\bmX|\Theta}(\bmx|\theta)}
\def \likelihoodf{f(\bmx|\theta)}
\def \likelihood{\ell(\theta|\bmx)}
%\def \jointDensity{f_{\Theta,\bmX}(\theta,\bmx)}
\def \jointDensity{f(\theta,\bmx)}
\def \BayesDenom{\int_{\Theta} \prior\likelihood~d\theta}



\DeclareFontShape{OT1}{cmr}{bx}{n}
  { <5> <6> <7> <8> <9> <10> <12> gen * cmbx
    <10.95> cmbx10
    <14.4> <17.28><20.74><24.88><43> cmbx12}{} 
\DeclareFixedFont{\bigfont}{OT1}{cmr}{bx}{n}{43pt}

%\notes
% use the following to get contents page etc for slides
%\notes\renewcommand{\slidepage}[1]{\newpage\setcounter{page}{#1}}
%

%\studnotes 
\smallnotes

\renewenvironment{center}
	{\begin{verse}
	Center:
	}
	{\end{verse}}
\newenvironment{example}
	{\begin{verse}
	Example:
	}
	{\end{verse}}
	
\begin{document}

%\input front
\thispagestyle{empty}
%\begin{center}
%\includegraphics[width=0.8\textwidth]{../graphics/DurhamUniversityLogo.png}

%\vspace{5cm}
%{\Large MATH3421}

%\vspace{2cm}
%{\Large Bayesian Computation and Modelling III}

%\vspace{3cm}
%{\LARGE Michaelmas, 2022--23}

%\vspace{2cm}\hspace*{-2mm}
%\end{center}

%\chapter*{MATH3421: Bayesian Computation and Modelling III}
%\section*{Michaelmas, 2022--23}

\rhead{Formative problems 3 solutions}
\chapter*{Formative problems 3 solutions}
\setcounter{page}{1}

\begin{enumerate}
\item 
%\begin{itemize}

(a) The full conditional density for $\theta_1$ is
\begin{align*}
\pi(\theta_1|\theta_2)&\propto \theta_1 \exp\{-\theta_1(\theta_2^2+1)\}, \quad \theta_1 >0.
\end{align*}
Hence, recognise
\[
\theta_1|\theta_2 \sim Gamma(2,\theta_2^2 +1).
\]
The full conditional density for $\theta_2$ is
\begin{align*}
\pi(\theta_2|\theta_1)&\propto \exp\left\{-\frac{1}{2}(\theta_2^2[2\theta_1+2]-4\theta_2)\right\}, \quad -\infty<\theta_2 <\infty\\
&\propto \exp\left\{-\frac{(2\theta_1+2)}{2}\left(\theta_2 - \frac{1}{\theta_1+1}\right)^2   \right\}, \quad -\infty<\theta_2 <\infty .
\end{align*}
Hence, recognise
\[
\theta_2|\theta_1 \sim N\left(\frac{1}{\theta_1+1}\,,\,\frac{1}{2(\theta_1+1)}\right).
\]
The algorithm is then:
\begin{enumerate}
\item[1.] Initialise with $\theta_1^{(0)}>0$ and $\theta_2^{(0)}\in \mathbb{R}$. Set $j=1$. 
\item[2.] Obtain a new value $\bmtheta^{(j)}$ from
  $\bmtheta^{(j-1)}$ by successive generation of values
\begin{itemize}
\item $\theta_1^{(j)}\sim Gamma\left(2,\left(\theta_2^{(j-1)}\right)^2 +1\right)$
\item $\theta_2^{(j)}\sim N\left(\frac{1}{\theta_1^{(j)}+1}\,,\,\frac{1}{2(\theta_1^{(j)}+1)}\right).$
\end{itemize}
\item[3.] If $j=N$, stop, otherwise put $j$ to $j+1$, and return to step 2.
\end{enumerate}

(b) The transition density is
\begin{align*}
p(\boldsymbol{\phi}|\boldsymbol{\theta})&=p(\phi_1,\phi_2|\theta_1,\theta_2)\\
&=\pi(\phi_1|\theta_2)\pi(\phi_2|\phi_1)\\
&=Gamma(\phi_1; 2, \theta_2^2 +1) \times N\left(\phi_2; \frac{1}{\phi_1+1}\,,\,\frac{1}{2(\phi_1+1)}\right), \phi_1>0, -\infty < \phi_2 < \infty
\end{align*}
assuming that the components were updated in order (first, second). The densities can be given 
explicitly if desired (but not required for full marks).
%\end{itemize}

\item 
%\begin{itemize}

(a) 
%\begin{itemize}

(i) We are told that $\bmpsi$ is Gaussian. The component means are
\[
\E(\psi_1)=\E(\psi_2)=0
\]
upon using linearity of expectation and the expectations of $\theta_1$ and $\theta_2$. 
The component variances are
\begin{align*}
\V(\psi_1)&=\frac{1}{2}(\V(\theta_1) +\V(\theta_2)+2\textrm{Cov}(\theta_1,\theta_2))\\
&=1+\rho.
\end{align*}
\begin{align*}
\V(\psi_2)&=\frac{1}{2}(\V(\theta_1) +\V(\theta_2)-2\textrm{Cov}(\theta_1,\theta_2))\\
&=1-\rho.
\end{align*}
Finally, we have
\begin{align*}
\textrm{Cov}(\psi_1,\psi_2)&=\frac{1}{2}\textrm{Cov}(\theta_1+\theta_2\,,\,\theta_1-\theta_2)\\
&= \frac{1}{2}(\V(\theta_1)-\V(\theta_2)+\textrm{Cov}(\theta_1,\theta_2)-\textrm{Cov}(\theta_1,\theta_2))\\
&=0.
\end{align*}
Hence,
\[
\begin{pmatrix} \psi_1 \\ \psi_2 \end{pmatrix} \sim 
N\left\{\begin{pmatrix} 0 \\ 0 \end{pmatrix}\,,\, \begin{pmatrix} 1+\rho & 0\\ 0 & 1-\rho \end{pmatrix}   \right\}.
\]
That is, $\psi_1 \sim N(0,1+\rho)$ and $\psi_2\sim N(0,1-\rho)$ independently. 

(ii) The Gibbs sampler collapses into draws of $\psi_1$ and $\psi_2$ from 
their respective marginal distributions. The result is direct sampling and we can think of the 
resulting Markov chain as zero order. The R code we need is

\begin{lstlisting}[language=R]
rho=0.99
psi1=rnorm(1000,0,sqrt(1+rho))
psi2=rnorm(1000,0,sqrt(1-rho))
#plot(ts(psi1)) #trace plot, etc
\end{lstlisting}

(iii) The mixing is unaffected by the choice of $\rho$.
%\end{itemize}

(b) 
%\begin{itemize}

(i) We know that each component of $\tilde{\bmtheta}$ is a linear combination of (jointly) 
Gaussian random variables. Hence, the distribution of $\tilde{\bmtheta}$ is Gaussian with mean 
and variance matrix to be determined. We have that
\[
\E(\tilde{\theta}_1)=\E(\tilde{\theta}_2)=0.
\]
For the component (marginal) variances, we have
\begin{align*}
\V(\tilde{\theta}_1)&=\frac{1}{2}(\V(\psi_1)+\V(\psi_2))\\
&=\frac{1}{2}(1+\rho+(1-\rho))\\
&=1 = \V(\tilde{\theta}_2).
\end{align*}
Finally, the covariance is
\begin{align*}
\textrm{Cov}(\tilde{\theta}_1,\tilde{\theta}_2)&= \textrm{Cov}\left(\frac{1}{\sqrt{2}}(\psi_1+\psi_2),\frac{1}{\sqrt{2}}(\psi_1-\psi_2)\right)\\
&=\frac{1}{2} (\V(\psi_1)-\V(\psi_2))\\
&=\rho.
\end{align*}
Thus, the distribution we require is
\[
\begin{pmatrix} \tilde{\theta}_1 \\ \tilde{\theta}_2 \end{pmatrix} \sim 
N\left\{\begin{pmatrix} 0 \\ 0 \end{pmatrix}\,,\, \begin{pmatrix} 1 & \rho\\ \rho & 1 \end{pmatrix}   \right\}.
\]

(ii) The following R code will do the job:

\begin{lstlisting}[language=R]
tildetheta1=(psi1+psi2)/sqrt(2)
tildetheta2=(psi1-psi2)/sqrt(2)
#plot(ts(tildetheta1)) #trace plot, etc
\end{lstlisting}

(Aside: The behaviour of the resulting zero order Markov chain isn't affected by $\rho$, since it is constructed through direct sampling 
of $\bmpsi$.)  

(iii) Lots of possibilities here. The (zero order) $\tilde{\bmtheta}^{(n)}$ chain has a theoretical auto-correlation of zero at all non-zero lags. This is in stark 
contrast to the $\bmtheta^{(n)}$ chain from Example 3.2.1. (see also Lab 1) which will only exhibit this property when $\rho=0$. The effective sample size for the former chain is 1000 (theoretically) for both components. For the $\bmtheta^{(n)}$ chain, I get an ESS of around 11 (!) for both component chains. Trace plots and ACF plots can also be given for both chains, if desired. The point of this exercise 
is that it is often desirable to work with a reparameterised chain, which is carefully constructed to reduce (or remove) problematic 
correlation between components.    
%\end{itemize}

%\end{itemize}


\end{enumerate}




\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{example}
\end{example}

\cover{Copy down the solution.}{
\textbf{Solution.}

}
\eproof


